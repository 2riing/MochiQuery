import os
import uuid
import openai
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from tqdm import tqdm
from dotenv import load_dotenv

# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# âœ… Milvus ì—°ê²° (Dockerì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ê¸°ë³¸ í¬íŠ¸)
connections.connect("default", host="localhost", port="19530")
collection_name = "semantic_text_collection"

# ğŸ§¼ ê¸°ì¡´ ì‚­ì œ
# if utility.has_collection(collection_name):
#     Collection(collection_name).drop()
#     print("ğŸ—‘ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ")

# ğŸ“ ìŠ¤í‚¤ë§ˆ ì •ì˜
fields = [
    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=255, is_primary=True),
    FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=64), # íŒŒì¼ ì¶œì²˜
    # ê³µí†µ ë˜ëŠ” ì¡°ê±´ë¶€ í•„ë“œ
    FieldSchema(name="term", dtype=DataType.VARCHAR, max_length=1024),
    FieldSchema(name="column_info", dtype=DataType.VARCHAR, max_length=1024),
    FieldSchema(name="question", dtype=DataType.VARCHAR, max_length=2048),
    FieldSchema(name="raw_ddl", dtype=DataType.VARCHAR, max_length=30000),
    FieldSchema(name="table_meta", dtype=DataType.VARCHAR, max_length=2048),
    # ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ & ë²¡í„°
    FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=32768),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=3072),
]

# ì»¬ë ‰ì…˜ ìƒì„±
schema = CollectionSchema(fields)
collection = Collection(name=collection_name, schema=schema)

# embedding í•„ë“œì— ì¸ë±ìŠ¤ ìƒì„±
collection.create_index(
    field_name="embedding",
    index_params={
        "metric_type": "COSINE",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 128}
    }
)

print(f"ğŸ“¦ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì™„ë£Œ")

# ğŸ“Œ ì„ë² ë”© í•¨ìˆ˜
def get_embedding(text):
    response = openai.Embedding.create(
        model="text-embedding-3-large",
        input=text
    )
    return response.data[0].embedding

# ğŸ“ íŒŒì¼ ëª©ë¡ ë° ë§¤í•‘
data_path = "../data"
file_map = {
    "biz_term_sentences.txt": ("term", "biz_term"),
    "column_info_sentences.txt": ("column_info", "column_info"),
    "custom_fewshot_sql_sentences.txt": ("question", "custom_sql"),
    "ddl_sentences.txt": ("raw_ddl", "ddl"),
    "table_meta_sentences.txt": ("table_meta", "table_meta"),
}

# ğŸ“¥ ë°ì´í„° ì½ê³  insert
for filename, (target_field, source_name) in file_map.items():
    file_path = os.path.join(data_path, filename)
    print(f"ğŸ“„ Processing: {filename}")

    with open(file_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    for line in tqdm(lines):
        text = line.strip()
        if not text:
            continue

        doc_id = str(uuid.uuid4())
        embedding = get_embedding(text)

        # ëª¨ë“  í•„ë“œëŠ” ê¸°ë³¸ê°’ "" ë˜ëŠ” None
        record = {
            "id": doc_id,
            "source": source_name,
            "term": "",
            "column_info": "",
            "question": "",
            "raw_ddl": "",
            "table_meta": "",
            "text": text,
            "embedding": embedding,
        }
        record[target_field] = text

        # ìˆœì„œëŒ€ë¡œ insert
        collection.insert([
            [record["id"]],
            [record["source"]],
            [record["term"]],
            [record["column_info"]],
            [record["question"]],
            [record["raw_ddl"]],
            [record["table_meta"]],
            [record["text"]],
            [record["embedding"]],
        ])
        
    collection.flush()

print("âœ… ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
